{"id": "2537714a-7744-4d43-9d19-e617c9910f09", "output": {"captions": [{"caption": "a man is standing", "bounding_box": [798, 375, 178, 288], "confidence": 0.9783499240875244}, {"caption": "a woman is wearing a white shirt", "bounding_box": [110, 238, 288, 425], "confidence": 0.9524353742599487}, {"caption": "the people are standing", "bounding_box": [0, 74, 890, 589], "confidence": 0.9489482045173645}, {"caption": "a woman is standing", "bounding_box": [648, 105, 349, 558], "confidence": 0.9047335386276245}, {"caption": "a white and blue striped shirt", "bounding_box": [489, 519, 140, 144], "confidence": 0.8824878334999084}, {"caption": "a man is wearing a white shirt", "bounding_box": [88, 131, 210, 248], "confidence": 0.8687654733657837}, {"caption": "the mans hair is black", "bounding_box": [244, 280, 116, 100], "confidence": 0.8672661185264587}, {"caption": "a woman is wearing a black jacket", "bounding_box": [392, 278, 161, 342], "confidence": 0.8618468642234802}, {"caption": "the curtains are black", "bounding_box": [89, 0, 886, 65], "confidence": 0.8603085279464722}, {"caption": "a bottle of a person", "bounding_box": [228, 432, 202, 206], "confidence": 0.8247730731964111}, {"caption": "a blue shirt", "bounding_box": [536, 501, 92, 131], "confidence": 0.8244541883468628}, {"caption": "the word <unk>", "bounding_box": [0, 26, 365, 120], "confidence": 0.8058768510818481}, {"caption": "a white and black <unk>", "bounding_box": [378, 461, 402, 201], "confidence": 0.7738983035087585}, {"caption": "a man wearing a hat", "bounding_box": [144, 102, 106, 116], "confidence": 0.7701127529144287}, {"caption": "a man is wearing a black shirt", "bounding_box": [665, 379, 135, 272], "confidence": 0.7270687222480774}, {"caption": "the head of a man", "bounding_box": [768, 174, 86, 95], "confidence": 0.7103657722473145}, {"caption": "the head of a person", "bounding_box": [809, 318, 115, 106], "confidence": 0.7099913358688354}, {"caption": "the head of a man", "bounding_box": [710, 438, 82, 98], "confidence": 0.6987002491950989}, {"caption": "a man in a black shirt", "bounding_box": [282, 115, 66, 118], "confidence": 0.6653631925582886}, {"caption": "a woman is wearing a black shirt", "bounding_box": [231, 112, 299, 550], "confidence": 0.6585349440574646}, {"caption": "the sign is black", "bounding_box": [255, 59, 108, 106], "confidence": 0.641645073890686}, {"caption": "the shirt is black", "bounding_box": [681, 515, 102, 86], "confidence": 0.6381831765174866}, {"caption": "the head of a person", "bounding_box": [202, 271, 258, 175], "confidence": 0.6141170263290405}, {"caption": "the fridge is white", "bounding_box": [0, 565, 604, 98], "confidence": 0.6043853759765625}, {"caption": "a woman with a black hair", "bounding_box": [625, 166, 58, 108], "confidence": 0.6021512746810913}, {"caption": "the wall is made of brick", "bounding_box": [362, 42, 634, 315], "confidence": 0.5736203789710999}, {"caption": "the people are standing", "bounding_box": [514, 104, 278, 540], "confidence": 0.5736070275306702}, {"caption": "a woman is looking at the table", "bounding_box": [469, 106, 201, 219], "confidence": 0.5612571835517883}, {"caption": "the white pole", "bounding_box": [705, 532, 118, 130], "confidence": 0.5463733673095703}]}}