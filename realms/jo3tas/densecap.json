{"id": "782bae74-894b-4d24-9117-5c7ec6696f88", "output": {"captions": [{"caption": "a woman is wearing a black jacket", "bounding_box": [403, 230, 206, 305], "confidence": 0.9649978876113892}, {"caption": "a woman is holding a wii", "bounding_box": [85, 25, 440, 510], "confidence": 0.96407151222229}, {"caption": "a white cup", "bounding_box": [65, 421, 64, 66], "confidence": 0.9596132636070251}, {"caption": "a man wearing a striped shirt", "bounding_box": [38, 88, 273, 312], "confidence": 0.951132595539093}, {"caption": "the word <unk>", "bounding_box": [47, 35, 336, 73], "confidence": 0.8996959924697876}, {"caption": "a white and brown tie", "bounding_box": [228, 170, 43, 80], "confidence": 0.8950284719467163}, {"caption": "the mans hair is black", "bounding_box": [141, 86, 83, 77], "confidence": 0.8881514072418213}, {"caption": "a sign on the table", "bounding_box": [510, 129, 75, 56], "confidence": 0.8838217854499817}, {"caption": "a striped shirt", "bounding_box": [142, 128, 147, 134], "confidence": 0.8712919354438782}, {"caption": "the man is wearing a black jacket", "bounding_box": [285, 45, 181, 347], "confidence": 0.8643988370895386}, {"caption": "a white cup", "bounding_box": [21, 391, 124, 120], "confidence": 0.8529388904571533}, {"caption": "a red glove", "bounding_box": [356, 397, 71, 82], "confidence": 0.8522651195526123}, {"caption": "a white box", "bounding_box": [82, 503, 132, 32], "confidence": 0.8252363204956055}, {"caption": "a white plastic bag", "bounding_box": [55, 238, 85, 230], "confidence": 0.8129415512084961}, {"caption": "the picture is in the background", "bounding_box": [10, 0, 644, 258], "confidence": 0.8067193031311035}, {"caption": "the man is wearing a white shirt", "bounding_box": [562, 410, 77, 125], "confidence": 0.7715492248535156}, {"caption": "the legs are black", "bounding_box": [252, 447, 139, 88], "confidence": 0.7476087808609009}, {"caption": "a blue and white bag", "bounding_box": [522, 3, 127, 139], "confidence": 0.7443004846572876}, {"caption": "the word <unk>", "bounding_box": [204, 51, 226, 37], "confidence": 0.6818011999130249}, {"caption": "a man holding a white bag", "bounding_box": [5, 179, 161, 356], "confidence": 0.6784600615501404}, {"caption": "the pants are black", "bounding_box": [197, 341, 283, 194], "confidence": 0.6575719118118286}, {"caption": "a pink and white striped tie", "bounding_box": [381, 436, 91, 99], "confidence": 0.6544139385223389}, {"caption": "a picture of a person", "bounding_box": [441, 0, 189, 284], "confidence": 0.6421900987625122}, {"caption": "a white and white striped awning", "bounding_box": [0, 101, 109, 121], "confidence": 0.6159797310829163}, {"caption": "the jacket is black", "bounding_box": [66, 166, 132, 154], "confidence": 0.5983806848526001}, {"caption": "a striped shirt", "bounding_box": [329, 120, 87, 193], "confidence": 0.5546068549156189}, {"caption": "the word <unk>", "bounding_box": [7, 43, 113, 51], "confidence": 0.5452603101730347}, {"caption": "a person is on the wall", "bounding_box": [589, 23, 65, 226], "confidence": 0.5009646415710449}]}}