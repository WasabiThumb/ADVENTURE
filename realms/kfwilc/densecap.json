{"id": "1c95211c-3045-4613-ba6d-9f85813d030a", "output": {"captions": [{"caption": "a woman holding a camera", "bounding_box": [30, 558, 318, 682], "confidence": 0.9930222630500793}, {"caption": "a man holding a umbrella", "bounding_box": [11, 0, 794, 1240], "confidence": 0.9865388870239258}, {"caption": "the head of a boy", "bounding_box": [422, 6, 185, 185], "confidence": 0.9356598854064941}, {"caption": "a green and green book", "bounding_box": [826, 78, 90, 314], "confidence": 0.9335764050483704}, {"caption": "a window on the wall", "bounding_box": [0, 165, 61, 270], "confidence": 0.9140447378158569}, {"caption": "a woman holding a rope", "bounding_box": [256, 82, 388, 718], "confidence": 0.887839138507843}, {"caption": "a black cord", "bounding_box": [688, 1059, 228, 180], "confidence": 0.8425576686859131}, {"caption": "a boy is wearing a black shirt", "bounding_box": [349, 54, 346, 244], "confidence": 0.8241655230522156}, {"caption": "a metal rack", "bounding_box": [308, 815, 149, 410], "confidence": 0.805534839630127}, {"caption": "a boy is holding a toothbrush", "bounding_box": [84, 517, 196, 379], "confidence": 0.7688165903091431}, {"caption": "a woman is holding a cell phone", "bounding_box": [0, 90, 258, 1149], "confidence": 0.7641552090644836}, {"caption": "the head of a man", "bounding_box": [132, 537, 137, 157], "confidence": 0.7399806976318359}, {"caption": "the window is white", "bounding_box": [822, 447, 95, 736], "confidence": 0.734308123588562}, {"caption": "the jeans are blue", "bounding_box": [93, 881, 160, 357], "confidence": 0.7252240180969238}, {"caption": "the wall is white", "bounding_box": [267, 666, 649, 573], "confidence": 0.6886399984359741}, {"caption": "the window is white", "bounding_box": [0, 472, 62, 273], "confidence": 0.677091658115387}, {"caption": "a metal rack", "bounding_box": [508, 848, 146, 391], "confidence": 0.6627508401870728}, {"caption": "a white fence", "bounding_box": [455, 272, 292, 930], "confidence": 0.6218624711036682}, {"caption": "a black and white bag", "bounding_box": [736, 1188, 180, 50], "confidence": 0.5889387726783752}, {"caption": "the arm of a person", "bounding_box": [3, 654, 162, 454], "confidence": 0.584242045879364}, {"caption": "a man holding a rope", "bounding_box": [210, 360, 290, 829], "confidence": 0.5600121021270752}, {"caption": "the hand of a person", "bounding_box": [25, 930, 65, 123], "confidence": 0.5179483890533447}]}}